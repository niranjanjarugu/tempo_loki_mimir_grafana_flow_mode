server:
  log_level: debug

# Configures a metrics scraping service, used to scrape metrics and send
# to Mimir.
metrics:
  # The `global` section pertains to the Prometheus `global` configuration.
  # See https://prometheus.io/docs/prometheus/latest/configuration/configuration/
  global:
    scrape_interval: 15s # By default, scrape targets every 15 seconds.
    # Remote write to the locally running Mimir service.
    remote_write:
      - url: http://mimir:9009/api/v1/push
        send_exemplars: true

  # Define a set of configurations for scraping by Grafana Agent.
  configs:
    - name: mimir
      # The `scrape_configs` section pertains to the Prometheus `scrape_configs`
      # configuration block.
      # See https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config
      scrape_configs:
        # Scrape Mimir metrics.
        - job_name: 'mimir'
          static_configs:
            - targets: ['mimir:9009']
              labels:
                service: 'mimir'
                group: 'infrastructure'

        # Scrape Loki metrics.
        - job_name: 'loki'
          static_configs:
            - targets: ['loki:3100']
              labels:
                service: 'loki'
                group: 'infrastructure'

        # Scrape Tempo metrics.
        - job_name: 'tempo'
          static_configs:
            - targets: ['tempo:3200']
              labels:
                service: 'tempo'
                group: 'infrastructure'

# Enable integrations.
# All metrics scraped from these integrations will use the `remote_write` block
# in the `global` configuration, above.
integrations:
  # Scrape metrics data from the Agent itself.
  agent:
    enabled: true
  # Scrape metrics data from the in-built Node Exporter instance.
  node_exporter:
    enabled: true

# Configures a log ingestion endpoint. This is used for the autologging feature in the tracing configuration below.
logs:
  # Define a single Promtail (logs) instance.
  # See https://grafana.com/docs/loki/latest/clients/promtail/
  configs:
    # Create a Promtail instance named `loki`, that pushes all log data to the locally running Loki service and
    # adds an external label for the job.
    - name: loki
      clients:
        - url: http://loki:3100/loki/api/v1/push
          external_labels:
            job: agent
  positions_directory: /tmp/positions

# Configure trace receiving.
traces:
  # Define a single trace configuration (each being a Tempo instance), named `tempo`.
  configs:
    - name: tempo
      # Add a custom attribute to every received span. This processor follows the conventions for the OpenTelemetry
      # collector attribute processor.
      # See https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/attributesprocessor/README.md
      attributes:
        actions:
          - key: vnodSample
            action: insert
            value: VnodValue
      # Define the protocols to receive traces in. In this case, OTLP gRPC on the default port (4317).
      # See https://grafana.com/docs/agent/latest/configuration/traces-config/ receivers.
      receivers:
        otlp:
          protocols:
            grpc:
      # Generate logs automatically from incoming trace data.
      automatic_logging:
        # Use the logs instance defined at the start of the configuration file, specifying a logs instance and the
        # named Promtail instance.
        backend: logs_instance
        logs_instance_name: loki
        # Ensure one log one line per root span (ie. one per trace).
        roots: true
        processes: false
        # Setting spans to `true` (default false) will generate a log line *per span* received. Note that this
        # can produce a huge amount of log information.
        spans: false
        # If present in the span, add the http.method, http.target and http.status_code span attributes to the log line.
        span_attributes:
          - http.method
          - http.target
          - http.status_code
        # Force the trace ID to be set as `traceId`. This ensures correlation from within Grafana between data sources.
        overrides:
          trace_id_key: "traceId"
      # Send batched traces to the locally running Tempo service.
      remote_write:
        - endpoint: tempo:4317
          insecure: true

      # NOTE: The below configuration has been commented out as span and service graph
      #       metrics generation is now handled by the Tempo service. However, the configuration
      #       is left as an example of how Grafana Agent could be used to generate them.
      #
      # Generate Prometheus metrics from the incoming trace spans.
      spanmetrics:
        # Add the http.target, http.method and http.status_code span attributes as labels for the metrics data.
        dimensions:
          - name: http.method
          - name: http.target
          - name: http.status_code
          - name: service.version
        # Use the `mimir` metrics configuration above as the basis for sending metrics to Mimir.
        # Note that this won't get scraped, it'll simply use the `remote_write` configuration.
        metrics_instance: mimir
      # Enable service graphs for visual representation of services within Grafana.
      service_graphs:
        enabled: true

      # An example of how to configure the tail sampler.
      # Remove these comments to only sample traces which contain erroring spans.
      #tail_sampling:
      #  policies:
      #    - type: status_code
      #      status_code:
      #        status_codes:
      #          - ERROR
